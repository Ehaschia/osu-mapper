{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data-example/tmp.json') as f:\n",
    "    raw_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = raw_data[1]\n",
    "Y = [raw_data[0][i][4:8] for i in range(len(X))]\n",
    "PX = [raw_data[0][i][0]+raw_data[0][i][2] for i in range(len(X))]\n",
    "PY = [raw_data[0][i][1]+raw_data[0][i][3] for i in range(len(X))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = [X, X, X]  # [3 * 448 * 65]\n",
    "Y = [Y, Y, Y]  # [3 * 448 * 4]\n",
    "PX = [PX, PX, PX]  # [3 * 448]\n",
    "PY = [PY, PY, PY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 448 65\n",
      "3 448 4\n",
      "3 448\n"
     ]
    }
   ],
   "source": [
    "music_len = 448\n",
    "print len(X), len(X[0]), len(X[0][0])\n",
    "print len(Y), len(Y[0]), len(Y[0][0])\n",
    "print len(PX), len(PX[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "num_hidden = 200\n",
    "X_len = 65\n",
    "Y_len = 4\n",
    "\n",
    "no_of_batches = int(len(X) / batch_size)\n",
    "epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "data = tf.placeholder(tf.float32, [None, music_len, X_len])\n",
    "target = tf.placeholder(tf.float32, [None, music_len, Y_len])\n",
    "target_PX = tf.placeholder(tf.float32, [None, music_len])\n",
    "target_PY = tf.placeholder(tf.float32, [None, music_len])\n",
    "\n",
    "dfm = {data:X, target:Y, target_PX:PX, target_PY:PY}\n",
    "\n",
    "cell = tf.nn.rnn_cell.LSTMCell(num_hidden, state_is_tuple=True)\n",
    "output, state = tf.nn.dynamic_rnn(cell, data, dtype=tf.float32)\n",
    "# output: [batch, length, feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weight = tf.Variable(tf.truncated_normal([num_hidden, Y_len]))\n",
    "bias = tf.Variable(tf.constant(0.0, shape=[Y_len]))\n",
    "\n",
    "weight_PX = tf.Variable(tf.truncated_normal([num_hidden, 1]))\n",
    "bias_PX = tf.Variable(tf.constant(0.5, shape=[1]))\n",
    "\n",
    "weight_PY = tf.Variable(tf.truncated_normal([num_hidden, 1]))\n",
    "bias_PY = tf.Variable(tf.constant(0.5, shape=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val = tf.reshape(output, [-1, num_hidden])\n",
    "tar = tf.reshape(target, [-1, Y_len])\n",
    "tar_PX = tf.reshape(target_PX, [-1])\n",
    "tar_PY = tf.reshape(target_PY, [-1])\n",
    "\n",
    "preds = tf.matmul(val, weight) + bias\n",
    "preds_PX = tf.sigmoid(tf.reshape(tf.matmul(val, weight_PX) + bias_PX, [-1]))\n",
    "preds_PY = tf.sigmoid(tf.reshape(tf.matmul(val, weight_PY) + bias_PY, [-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_ens = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(preds, tar))\n",
    "l2_PX = tf.reduce_mean(tf.nn.l2_loss(preds_PX - tar_PX))\n",
    "l2_PY = tf.reduce_mean(tf.nn.l2_loss(preds_PY - tar_PY))\n",
    "\n",
    "losses = 100 * cross_ens + l2_PX + l2_PY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer()\n",
    "minimize = optimizer.minimize(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mistakes = tf.not_equal(tf.argmax(tar, 1), tf.argmax(preds, 1))\n",
    "error = tf.reduce_mean(tf.cast(mistakes, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303.681\n"
     ]
    }
   ],
   "source": [
    "print sess.run(losses, dfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 loss 80.695610\n",
      "Epoch  2 loss 76.433853\n",
      "Epoch  3 loss 72.105530\n",
      "Epoch  4 loss 66.979706\n",
      "Epoch  5 loss 62.400642\n",
      "Epoch  6 loss 58.457840\n",
      "Epoch  7 loss 55.449379\n",
      "Epoch  8 loss 52.921150\n",
      "Epoch  9 loss 50.323631\n",
      "Epoch 10 loss 47.787582\n",
      "Epoch 11 loss 45.712944\n",
      "Epoch 12 loss 44.207130\n",
      "Epoch 13 loss 42.386452\n",
      "Epoch 14 loss 40.818974\n",
      "Epoch 15 loss 38.923786\n",
      "Epoch 16 loss 36.910561\n",
      "Epoch 17 loss 35.205547\n",
      "Epoch 18 loss 34.062664\n",
      "Epoch 19 loss 32.910248\n",
      "Epoch 20 loss 31.846874\n",
      "Epoch 21 loss 30.813692\n",
      "Epoch 22 loss 29.568481\n",
      "Epoch 23 loss 28.451324\n",
      "Epoch 24 loss 27.091072\n",
      "Epoch 25 loss 26.276802\n",
      "Epoch 26 loss 25.756454\n",
      "Epoch 27 loss 24.890463\n",
      "Epoch 28 loss 23.834518\n",
      "Epoch 29 loss 22.988739\n",
      "Epoch 30 loss 22.639149\n",
      "Epoch 31 loss 22.185116\n",
      "Epoch 32 loss 21.564281\n",
      "Epoch 33 loss 21.267155\n",
      "Epoch 34 loss 20.987957\n",
      "Epoch 35 loss 20.720852\n",
      "Epoch 36 loss 20.262810\n",
      "Epoch 37 loss 19.990379\n",
      "Epoch 38 loss 19.676365\n",
      "Epoch 39 loss 19.221210\n",
      "Epoch 40 loss 18.322138\n",
      "Epoch 41 loss 17.734787\n",
      "Epoch 42 loss 17.570114\n",
      "Epoch 43 loss 17.370483\n",
      "Epoch 44 loss 16.931952\n",
      "Epoch 45 loss 15.631927\n",
      "Epoch 46 loss 14.766352\n",
      "Epoch 47 loss 14.233723\n",
      "Epoch 48 loss 13.944502\n",
      "Epoch 49 loss 13.716229\n",
      "Epoch 50 loss 13.467610\n",
      "Epoch 51 loss 13.347408\n",
      "Epoch 52 loss 13.227669\n",
      "Epoch 53 loss 12.996120\n",
      "Epoch 54 loss 12.828165\n",
      "Epoch 55 loss 12.787100\n",
      "Epoch 56 loss 12.694249\n",
      "Epoch 57 loss 12.623706\n",
      "Epoch 58 loss 12.543451\n",
      "Epoch 59 loss 12.412544\n",
      "Epoch 60 loss 12.252710\n",
      "Epoch 61 loss 12.228109\n",
      "Epoch 62 loss 12.201544\n",
      "Epoch 63 loss 12.137861\n",
      "Epoch 64 loss 12.092452\n",
      "Epoch 65 loss 12.059166\n",
      "Epoch 66 loss 11.982505\n",
      "Epoch 67 loss 11.835373\n",
      "Epoch 68 loss 11.687117\n",
      "Epoch 69 loss 10.924901\n",
      "Epoch 70 loss 10.519979\n",
      "Epoch 71 loss 10.429502\n",
      "Epoch 72 loss 10.282987\n",
      "Epoch 73 loss 10.053658\n",
      "Epoch 74 loss 9.730114\n",
      "Epoch 75 loss 9.760288\n",
      "Epoch 76 loss 9.702610\n",
      "Epoch 77 loss 9.557104\n",
      "Epoch 78 loss 9.430788\n",
      "Epoch 79 loss 9.364077\n",
      "Epoch 80 loss 9.342463\n",
      "Epoch 81 loss 9.307802\n",
      "Epoch 82 loss 9.275885\n",
      "Epoch 83 loss 9.249990\n",
      "Epoch 84 loss 9.220831\n",
      "Epoch 85 loss 9.190582\n",
      "Epoch 86 loss 9.155108\n",
      "Epoch 87 loss 9.112161\n",
      "Epoch 88 loss 9.061728\n",
      "Epoch 89 loss 9.000595\n",
      "Epoch 90 loss 8.932901\n",
      "Epoch 91 loss 8.869955\n",
      "Epoch 92 loss 8.795825\n",
      "Epoch 93 loss 8.749151\n",
      "Epoch 94 loss 8.725207\n",
      "Epoch 95 loss 8.637186\n",
      "Epoch 96 loss 8.432405\n",
      "Epoch 97 loss 8.458108\n",
      "Epoch 98 loss 8.400217\n",
      "Epoch 99 loss 8.278264\n",
      "Epoch 100 loss 8.256849\n"
     ]
    }
   ],
   "source": [
    "for i in range(epoch):\n",
    "    ptr = 0\n",
    "    for j in range(no_of_batches):\n",
    "        inp, out, out_PX, out_PY = X[ptr:ptr+batch_size], Y[ptr:ptr+batch_size], PX[ptr:ptr+batch_size], PY[ptr:ptr+batch_size]\n",
    "        ptr += batch_size\n",
    "        sess.run(minimize, {data: inp, target: out, target_PX: out_PX, target_PY: out_PY})\n",
    "    incor = sess.run(error, dfm)\n",
    "    loss = sess.run(losses, dfm)\n",
    "    cross = sess.run(cross_ens, dfm)\n",
    "    lx = sess.run(l2_PX, dfm)\n",
    "    ly = sess.run(l2_PY, dfm)\n",
    "    print('Epoch {:2d} loss {:3.6f}'.format(i + 1, loss))\n",
    "#     print('         error {:3.6f}% cross {:3.6f} lx {:3.6f} ly {:3.6f}'.format(incor*100, cross, lx, ly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
